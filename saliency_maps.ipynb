{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Displaying break/ndUDTMBzJmU_020\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n(3, 256, 256)\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3287edbb4e66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# Get gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mguided_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGBP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguided_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mtotal_grad\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mguided_grads\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/danceClassification/visualizations/guided_backprop.py\u001b[0m in \u001b[0;36mgenerate_gradients\u001b[0;34m(self, input_image, target_class)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mone_hot_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_hot_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;31m# Convert Pytorch variable to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# [0] to get rid of the first channel (1,3,224,224)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from dataset import *\n",
    "from model.model import *\n",
    "from run import make_paths\n",
    "from utils.utils import *\n",
    "\n",
    "from visualizations.guided_backprop import *\n",
    "from visualizations.misc_functions import *\n",
    "\n",
    "\n",
    "######################################\n",
    "# Configurable items\n",
    "######################################\n",
    "# Key: name, value: # frames\n",
    "video_examples = { \n",
    "    \"break/ndUDTMBzJmU_020\" : 301,\n",
    "    \"swing/AehnnJzWO80_103\" : 251,\n",
    "    \"ballet/mSvNjhEPh7I_050\" : 201,\n",
    "    \"flamenco/7L4zXJ1OS6c_456\": 301,\n",
    "    \"foxtrot/ezbpkmExW30_035\": 301,\n",
    "    \"latin/iRntFnMArIU_206\": 301,\n",
    "    \"quickstep/QDiPQ7uBYY4_734\": 301,\n",
    "    \"square/RpbBVHlC8SU_056\": 241,\n",
    "    \"swing/AehnnJzWO80_103\": 251,\n",
    "    \"tango/8LMvAf5ftZ4_008\": 301,\n",
    "    \"waltz/AQmHJlhUhes_022\": 301, \n",
    "}\n",
    "# How many to skip when iterating through frames of video\n",
    "skip_size = 50\n",
    "# Which features to look at\n",
    "features = [0, 1]\n",
    "\n",
    "\n",
    "# Load trained models\n",
    "# some fixed paths\n",
    "image_dataset = rawImageDataset(\"/mnt/disks/disk1/processed/test_index.csv\")\n",
    "model = ModelChooser(\"resnet18_features\", 0)\n",
    "GBP = GuidedBackprop(model)\n",
    "\n",
    "for video in video_examples:\n",
    "    print(f\"Gradient for {video}\")\n",
    "    max = video_examples[video]\n",
    "    for i in range(1, max+1, skip_size):\n",
    "        total_grad = np.zeros((3, 256, 256))\n",
    "        for f in range(512):\n",
    "            d, id = os.path.split(video)\n",
    "            img_path = f\"/mnt/disks/disk1/raw/rgb/{video}_{i:04d}.jpg\"\n",
    "            orig_img = Image.open(img_path).resize((256, 256))\n",
    "            # Grab transformed X\n",
    "            X = image_dataset.get_X(img_path).unsqueeze(0)\n",
    "            X.requires_grad_()\n",
    "            # Get gradients\n",
    "            guided_grads = GBP.generate_gradients(X, f)\n",
    "            total_grad += guided_grads/512\n",
    "            # Save a couple specific neurons gradients\n",
    "            if f in features:\n",
    "                d, id = os.path.split(video)\n",
    "                save_gradient_images(guided_grads, f\"{d}_{id}_{i:04d}_f{f}_grad\")\n",
    "                #Visualize\n",
    "                guided_grads = format_np_output(guided_grads)\n",
    "                grad_img = Image.fromarray(guided_grads)\n",
    "                #Make side by side image\n",
    "                new_img = Image.new('RGB', (512, 256))\n",
    "                new_img.paste(orig_img, (0, 0))\n",
    "                new_img.paste(grad_img, (256, 0))\n",
    "                save_gradient_images(new_img, f\"{d}_{id}_{i:04d}_f{f}_full\")\n",
    "                # display(new_img)\n",
    "        #display final total gradient\n",
    "        img = format_np_output(total_grad)\n",
    "        img = Image.fromarray(img)\n",
    "        save_gradient_images(img, f\"{d}_{id}_{i:04d}_sum\")\n",
    "        display(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}